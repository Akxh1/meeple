# Mock Exam App - Project Goals & Research Context

## ðŸŽ¯ Purpose

This Mock Exam Application serves as a **data collection instrument** for a research project focused on building and validating a Machine Learning model for **Student Performance Prediction**. The app simulates an authentic exam environment to capture realistic behavioral and performance data from students.

---

## ðŸ“š Research Project Overview

### Project Title
> **"A 'Predict-Explain-Act' Framework for the LMS: Synthesizing Machine Learning Prediction, XAI Diagnostics, and LLM-Driven Adaptive Intervention."**

### Executive Summary

This research project addresses the **critical fragmentation in current educational technology**. While modern Learning Management Systems (LMS) collect vast amounts of data, they fail to close the loop between:
- **Identifying** a struggling student
- **Helping** them effectively

This project introduces a **unified framework** that synthesizes:

| Component | Role |
|-----------|------|
| **Machine Learning (ML)** | Predicts student risk and performance |
| **Explainable AI (XAI)** | Explains predictions to teachers in human-understandable terms |
| **Large Language Models (LLM)** | Automatically acts on insights to support students |

The goal is to create a system that not only **predicts** student risk but **explains** it to educators and **automatically acts** on it to support students.

---

## ðŸ”¬ Role of This App in the Research

### Primary Objective
Gather authentic exam interaction data to:
1. **Perform Exploratory Data Analysis (EDA)** to identify key features
2. **Build and validate an ML model** for student performance prediction
3. **Generate synthetic data** based on real patterns for model training and testing

### Data Collection Goals

The app captures the following categories of behavioral and performance data:

#### ðŸ“Š Performance Metrics
- Correct/incorrect answers per question
- Overall score and accuracy
- Performance breakdown by topic/module

#### â±ï¸ Temporal Patterns
- Time spent on each question
- Total exam duration
- Time distribution across difficulty levels
- Pacing patterns (rushing vs. deliberating)

#### ðŸ”„ Behavioral Signals
- Navigation patterns (forward/backward movement)
- Questions marked for review
- Answer changes and revision patterns
- Hesitation indicators

#### ðŸ§  Engagement Indicators
- Question skip patterns
- Hint usage (if applicable)
- Confidence indicators through review marking

---

## ðŸ—ï¸ The Predict-Explain-Act Framework

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         LMS DATA LAYER                          â”‚
â”‚         (Mock Exam App collects authentic exam data)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      1. PREDICT (ML Model)                      â”‚
â”‚  â€¢ Identifies at-risk students via Learning Mastery Score       â”‚
â”‚  â€¢ Predicts performance outcomes using 11 behavioral features   â”‚
â”‚  â€¢ Flags early warning signals based on 4-level classification  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      2. EXPLAIN (XAI Layer)                     â”‚
â”‚  â€¢ Translates predictions into understandable insights         â”‚
â”‚  â€¢ Shows teachers WHY a student is struggling                   â”‚
â”‚  â€¢ Highlights specific areas of concern                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      3. ACT (LLM Intervention)                  â”‚
â”‚  â€¢ Generates personalized learning recommendations              â”‚
â”‚  â€¢ Provides adaptive scaffolding to students                    â”‚
â”‚  â€¢ Creates targeted intervention strategies                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸŽ¯ Implemented Features (11 ML Features)

### Tier 1: Core 6 Features (Used for LMS Calculation)

These features have **strong research citations** and create the target variable:

| Feature | Description | LMS Role |
|---------|-------------|----------|
| `score_percentage` | Overall exam score (0-100%) | Base Performance (50%) |
| `hard_question_accuracy` | Accuracy on difficult questions | Deep Understanding (15%) |
| `hint_usage_percentage` | % of questions where hints used | Independence Penalty (-15) |
| `avg_confidence` | Self-reported confidence (1-5) | Calibration Bonus (+10) |
| `answer_changes_rate` | Answer changes per question | Stability Bonus (+10) |
| `tab_switches_rate` | Tab switches per question | Attention Bonus (+10) |

### Tier 2: Additional 5 Features (ML Predictors Only)

| Feature | Description | Purpose |
|---------|-------------|---------|
| `avg_time_per_question` | Average seconds per question | Processing speed |
| `review_percentage` | % of questions marked for review | Uncertainty indicator |
| `avg_first_action_latency` | Seconds before first click | Cognitive load |
| `clicks_per_question` | Total clicks per question | Engagement intensity |
| `performance_trend` | Score change 1stâ†’2nd half | Fatigue/improvement |

---

## ðŸ“ Learning Mastery Score (LMS)

### Formula
```
LMS = 0.50Ã—S + 0.15Ã—Hd + 10Ã—Ccal + 10Ã—Ks + 10Ã—Af âˆ’ 15Ã—Hu^1.5
```

### Why LMS â‰  Raw Score
| Scenario | Raw Score | LMS | Interpretation |
|----------|-----------|-----|----------------|
| High hints, low confidence | 80% | ~55 | Scaffolded performance |
| No hints, high confidence | 70% | ~78 | Independent mastery |
| Inconsistent answers | 75% | ~60 | Unstable knowledge |

### Mastery Level Classification
| Level | LMS Range | Color Code |
|-------|-----------|------------|
| At-Risk | 0-35 | ðŸ”´ Red |
| Developing | 36-55 | ðŸŸ  Orange |
| Proficient | 56-75 | ðŸ”µ Blue |
| Advanced | 76-100 | ðŸŸ¢ Green |

> Full algorithm details: See `/lms-explained` page in the app or `Performance_Prediction_Validation.md`

---

## ðŸ”„ Synthetic Data Generation

After EDA, the collected data patterns will be used to:
1. **Understand feature distributions** and correlations
2. **Generate synthetic datasets** using Cholesky decomposition
3. **Train ML models** on diverse, representative data
4. **Validate model performance** on held-out real data

---

## âœ… Implementation Status

| Component | Status | Notes |
|-----------|--------|-------|
| **Data Collection** | âœ… Complete | 11 features collected from exam interactions |
| **Admin Panel** | âœ… Complete | View students, export CSV, toggle ML features |
| **LMS Calculation** | âœ… Complete | Research-backed 6-component formula |
| **LMS Display** | âœ… Complete | Student table + profile with color-coded levels |
| **Algorithm Explanation** | âœ… Complete | `/lms-explained` page with full breakdown |
| **EDA Script** | âœ… Complete | `student_eda_synthetic_data.py` |
| **Research Validation** | âœ… Complete | `Performance_Prediction_Validation.md` |
| **ML Model** | âœ… Complete | Bagging Classifier (50 estimators, RÂ²â‰ˆ0.90) in `ml_model/` |
| **XAI Integration** | âœ… Complete | SHAP integration in Flask API + Laravel service |
| **LLM Intervention** | âœ… Complete | Adaptive hints via Gemini API with SHAP context |


---

## ðŸ“„ Project Documentation

| File | Purpose |
|------|---------|
| `PROJECT_GOALS.md` | This file - project overview and progress |
| `Performance_Prediction_Validation.md` | LMS formula justification with 30 research citations |
| `student_eda_synthetic_data.py` | Colab script for EDA and synthetic data generation |
| `citations_StudentPerformance.csv` | Research paper citations (personal use - gitignored) |

---

## ðŸ“ˆ Expected Outcomes

| Phase | Deliverable | Status |
|-------|-------------|--------|
| Data Collection | Rich exam interaction dataset | âœ… |
| EDA | Feature importance ranking, correlation analysis | âœ… |
| Model Development | Performance prediction ML model | ðŸ”² |
| XAI Integration | Interpretable explanations for predictions | ðŸ”² |
| LLM Integration | Automated intervention recommendations | ðŸ”² |

---

## ðŸ”— Connection to LMS Integration

This Mock Exam App serves as a **proof-of-concept** data source. The insights and models developed here will be:
- Adaptable to any LMS environment
- Scalable to larger student populations
- Generalizable across different subject domains

---

*Last Updated: January 2026*  
*Research Project: Predict-Explain-Act Framework for Intelligent LMS*

